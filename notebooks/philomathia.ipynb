{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb58f1b7",
   "metadata": {},
   "source": [
    "# Philomathia - Projet Mathématiques pour l'Intelligence Artificielle\n",
    "\n",
    "## Présentation du projet\n",
    "\n",
    "#### Les mathématiques : langage universel de la science ####\n",
    "\n",
    "### Mathématiques et Machine Learning\n",
    "\n",
    "- Les mathématiques forment le socle théorique de tous les algorithmes d'intelligence artificielle, de la régression linéaire aux réseaux de neurones profonds\n",
    "- Elles permettent de comprendre le fonctionnement des modèles, d'interpréter leurs résultats et d'optimiser leurs performances\n",
    "\n",
    "### Attendus du projet\n",
    "\n",
    "- Réaliser une veille scientifique sur des concepts mathématiques clés\n",
    "- Fournir pour chaque notion : définition rigoureuse, exemples concrets et vulgarisation accessible\n",
    "- Développer une double compétence : maîtrise théorique et capacité de transmission\n",
    "- Implémenter ces concepts en Python via un notebook pour une mise en pratique concrète\n",
    "\n",
    "---\n",
    "\n",
    "## Sommaire\n",
    "\n",
    "### I. Algèbre linéaire et statistiques descriptives\n",
    "1. Vecteur\n",
    "2. Matrice\n",
    "3. Moyenne, médiane, maximum, minimum\n",
    "4. Histogramme\n",
    "\n",
    "### II. Visualisation statistique et distributions\n",
    "1. Quartiles\n",
    "2. Boxplot\n",
    "3. Corrélation linéaire\n",
    "4. Théorème central limite\n",
    "\n",
    "### III. Probabilités et analyse statistique avancée\n",
    "1. Probabilité et loi de probabilité\n",
    "2. Variables indépendantes\n",
    "3. Espérance, variance et écart-type\n",
    "4. Dérivée\n",
    "\n",
    "### IV. Implémentation Python et mise en pratique\n",
    "\n",
    "Tout au long du notebook, chaque concept mathématique est accompagné d'une implémentation pratique en Python. Les exercices utilisent les bibliothèques NumPy pour les calculs, Matplotlib et Seaborn pour les visualisations, permettant ainsi d'ancrer la compréhension théorique par la manipulation concrète des données et des algorithmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5aeac8c7-b5fc-40a7-b15a-75a25b9c14d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8221408c-65c8-4fb8-b19a-9420276a2f86",
   "metadata": {},
   "source": [
    "## I. Algèbre linéaire et statistiques descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06a31910-d215-42b0-ae55-27ab54228054",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 3) (3753694367.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[55], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    En mathématiques, un **vecteur** est un objet qui a à la fois une **magnitude** (une longueur) et une **direction**. On peut le visualiser comme une flèche partant de l'origine dans un espace multidimensionnel.\u001b[0m\n\u001b[1;37m                                                                                                                                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 3)\n"
     ]
    }
   ],
   "source": [
    "### 1. Vecteurs\n",
    "\n",
    "En mathématiques, un **vecteur** est un objet qui a à la fois une **magnitude** (une longueur) et une **direction**. On peut le visualiser comme une flèche partant de l'origine dans un espace multidimensionnel.\n",
    "\n",
    "En science des données et en apprentissage automatique, les vecteurs sont omniprésents :\n",
    "\n",
    "*   **Représentation de données :** Chaque observation ou point de données est souvent représenté comme un vecteur, où chaque dimension correspond à une caractéristique (feature) de l'observation. Par exemple, les caractéristiques d'une maison (surface, nombre de chambres, prix) peuvent former un vecteur [150 m², 4, 300000 €].\n",
    "*   **Vecteurs de caractéristiques :** Dans les modèles, les caractéristiques d'entrée sont regroupées en vecteurs pour être traitées mathématiquement.\n",
    "*   **Poids des modèles :** Les paramètres (poids et biais) des modèles linéaires ou des réseaux de neurones sont souvent représentés sous forme de vecteurs ou de matrices.\n",
    "*   **Opérations vectorielles :** Des opérations comme l'addition de vecteurs (combiner des caractéristiques), la multiplication scalaire (changer l'échelle d'une caractéristique) ou le produit scalaire (mesurer la similarité ou projeter des vecteurs) sont fondamentales dans de nombreux algorithmes.\n",
    "\n",
    "Comprendre les vecteurs et leurs opérations est essentiel pour manipuler et analyser des données multidimensionnelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296345e-e735-48cf-ab21-324fd32e1ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer des vecteurs NumPy\n",
    "vec_a = np.array([2, 3])\n",
    "vec_b = np.array([1, -2])\n",
    "vec_c = np.array([4, 1, 5])  # Un vecteur 3D\n",
    "\n",
    "print(\"Vecteur A (2D) :\", vec_a)\n",
    "print(\"Vecteur B (2D) :\", vec_b)\n",
    "print(\"Vecteur C (3D) :\", vec_c)\n",
    "\n",
    "# Opérations vectorielles\n",
    "print(\"\\nOpérations vectorielles :\")\n",
    "\n",
    "# Addition (pour vecteurs de même dimension)\n",
    "somme_ab = vec_a + vec_b\n",
    "print(\"A + B =\", somme_ab)\n",
    "\n",
    "# Soustraction (pour vecteurs de même dimension)\n",
    "difference_ab = vec_a - vec_b\n",
    "print(\"A - B =\", difference_ab)\n",
    "\n",
    "# Multiplication scalaire\n",
    "scalaire = 2.5\n",
    "mult_scalaire_a = scalaire * vec_a\n",
    "print(f\"{scalaire} * A =\", mult_scalaire_a)\n",
    "\n",
    "# Produit scalaire (dot product) (pour vecteurs de même dimension)\n",
    "produit_scalaire_ab = np.dot(vec_a, vec_b)\n",
    "print(\"A . B (produit scalaire) =\", produit_scalaire_ab)\n",
    "\n",
    "# Visualisation d'un vecteur 2D\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Dessiner le vecteur A (de l'origine à [2, 3])\n",
    "plt.quiver(0, 0, vec_a[0], vec_a[1], angles='xy', scale_units='xy', scale=1, color='r', label='Vecteur A')\n",
    "\n",
    "# Dessiner le vecteur B (de l'origine à [1, -2])\n",
    "plt.quiver(0, 0, vec_b[0], vec_b[1], angles='xy', scale_units='xy', scale=1, color='b', label='Vecteur B')\n",
    "\n",
    "# Dessiner le vecteur Somme (A+B) sans linestyle\n",
    "plt.quiver(0, 0, somme_ab[0], somme_ab[1], angles='xy', scale_units='xy', scale=1, color='g', label='A + B')\n",
    "\n",
    "# Paramètres du graphique\n",
    "plt.xlim(-5, 5)\n",
    "plt.ylim(-5, 5)\n",
    "plt.xlabel('Axe X')\n",
    "plt.ylabel('Axe Y')\n",
    "plt.title('Visualisation de Vecteurs 2D et leur Somme')\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color='grey', lw=0.5)\n",
    "plt.axvline(0, color='grey', lw=0.5)\n",
    "plt.legend()\n",
    "plt.gca().set_aspect('equal', adjustable='box')  # Assurer que les axes ont la même échelle\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e98fc79-d468-423e-90da-94cc8906e637",
   "metadata": {},
   "source": [
    "### 2. Matrices\n",
    "\n",
    "Une **matrice** est un tableau rectangulaire de nombres, de symboles ou d'expressions organisés en lignes et en colonnes. Elle est définie par ses dimensions, notées m x n, où m est le nombre de lignes et n est le nombre de colonnes.\n",
    "\n",
    "Les matrices sont des outils fondamentaux en algèbre linéaire et jouent un rôle crucial en science des données et en intelligence artificielle pour plusieurs raisons :\n",
    "\n",
    "*   **Stockage de données :** Les ensembles de données sont souvent représentés sous forme de matrices, où chaque ligne correspond à une observation et chaque colonne à une caractéristique (feature).\n",
    "*   **Transformations linéaires :** Les matrices sont utilisées pour représenter des transformations linéaires dans l'espace vectoriel, comme les rotations, les mises à l'échelle ou les translations. Ces transformations sont au cœur de nombreux algorithmes, notamment en traitement d'images et en graphisme.\n",
    "*   **Systèmes d'équations linéaires :** Les matrices permettent de représenter et de résoudre efficacement des systèmes d'équations linéaires, ce qui est essentiel dans des domaines comme la régression linéaire.\n",
    "*   **Calculs dans les réseaux de neurones :** Les opérations matricielles, en particulier la multiplication matricielle, sont les opérations de base effectuées dans les couches des réseaux de neurones pour propager les signaux.\n",
    "*   **Réduction de dimensionnalité :** Des techniques comme l'Analyse en Composantes Principales (ACP) s'appuient fortement sur les opérations matricielles (comme la décomposition en valeurs singulières) pour réduire la dimensionnalité des données tout en préservant l'information importante.\n",
    "\n",
    "Comprendre les opérations matricielles (addition, soustraction, multiplication) est indispensable pour travailler avec des données structurées et construire des modèles d'apprentissage automatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024a314-df3e-4f03-bae2-9fc19e7efaac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 5. Create two NumPy matrices\n",
    "matrix_a = np.array([[1, 2],\n",
    "                     [3, 4]])\n",
    "\n",
    "matrix_b = np.array([[5, 6],\n",
    "                     [7, 8]])\n",
    "\n",
    "matrix_c = np.array([[1, 2, 3],\n",
    "                     [4, 5, 6]])\n",
    "\n",
    "matrix_d = np.array([[7, 8],\n",
    "                     [9, 10],\n",
    "                     [11, 12]])\n",
    "\n",
    "print(\"Matrice A (2x2):\")\n",
    "print(matrix_a)\n",
    "print(\"\\nMatrice B (2x2):\")\n",
    "print(matrix_b)\n",
    "print(\"\\nMatrice C (2x3):\")\n",
    "print(matrix_c)\n",
    "print(\"\\nMatrice D (3x2):\")\n",
    "print(matrix_d)\n",
    "\n",
    "\n",
    "# 6. Demonstrate matrix addition and subtraction\n",
    "print(\"\\nOpérations sur les matrices 2x2 (A et B):\")\n",
    "try:\n",
    "    somme_ab = matrix_a + matrix_b\n",
    "    print(\"A + B =\")\n",
    "    print(somme_ab)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur lors de l'addition de A et B: {e}\")\n",
    "\n",
    "try:\n",
    "    difference_ab = matrix_a - matrix_b\n",
    "    print(\"A - B =\")\n",
    "    print(difference_ab)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur lors de la soustraction de A et B: {e}\")\n",
    "\n",
    "# Addition/Soustraction entre matrices de dimensions incompatibles (devrait générer une erreur)\n",
    "print(\"\\nOpérations sur matrices de dimensions incompatibles (A et C):\")\n",
    "try:\n",
    "    somme_ac = matrix_a + matrix_c\n",
    "    print(\"A + C =\")\n",
    "    print(somme_ac)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur attendue lors de l'addition de A et C: {e}\")\n",
    "\n",
    "\n",
    "# 7. Demonstrate matrix multiplication\n",
    "# Multiplication A @ B (2x2 @ 2x2 -> 2x2)\n",
    "print(\"\\nMultiplication matricielle:\")\n",
    "try:\n",
    "    produit_ab = matrix_a @ matrix_b\n",
    "    # Alternative: np.dot(matrix_a, matrix_b)\n",
    "    print(\"A @ B =\")\n",
    "    print(produit_ab)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur lors de la multiplication A @ B: {e}\")\n",
    "\n",
    "# Multiplication C @ D (2x3 @ 3x2 -> 2x2)\n",
    "try:\n",
    "    produit_cd = matrix_c @ matrix_d\n",
    "    print(\"C @ D =\")\n",
    "    print(produit_cd)\n",
    "except ValueError as e:\n",
    "     print(f\"Erreur lors de la multiplication C @ D: {e}\")\n",
    "\n",
    "# Multiplication D @ C (3x2 @ 2x3 -> 3x3)\n",
    "try:\n",
    "    produit_dc = matrix_d @ matrix_c\n",
    "    print(\"D @ C =\")\n",
    "    print(produit_dc)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur lors de la multiplication D @ C: {e}\")\n",
    "\n",
    "# Multiplication A @ C (2x2 @ 2x3) - Compatible\n",
    "try:\n",
    "    produit_ac = matrix_a @ matrix_c\n",
    "    print(\"A @ C =\")\n",
    "    print(produit_ac)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur lors de la multiplication A @ C: {e}\")\n",
    "\n",
    "# Multiplication C @ A (2x3 @ 2x2) - Incompatible (nombre de colonnes de C != nombre de lignes de A)\n",
    "print(\"\\nMultiplication sur matrices de dimensions incompatibles (C @ A):\")\n",
    "try:\n",
    "    produit_ca = matrix_c @ matrix_a\n",
    "    print(\"C @ A =\")\n",
    "    print(produit_ca)\n",
    "except ValueError as e:\n",
    "    print(f\"Erreur attendue lors de la multiplication C @ A: {e}\")\n",
    "\n",
    "# 8. Demonstrate scalar multiplication\n",
    "scalaire = 3\n",
    "mult_scalaire_a = scalaire * matrix_a\n",
    "print(f\"\\nMultiplication scalaire ({scalaire} * A):\")\n",
    "print(mult_scalaire_a)\n",
    "\n",
    "\n",
    "# 9. Generate random data and plot transformation\n",
    "# Générer des points aléatoires 2D\n",
    "np.random.seed(42) # pour la reproductibilité\n",
    "points_originaux = np.random.rand(10, 2) * 5 # 10 points, coordonnées entre 0 et 5\n",
    "\n",
    "# Matrice de transformation (par exemple, une rotation + mise à l'échelle)\n",
    "matrice_transformation = np.array([[1.5, 1],\n",
    "                                  [-0.5, 1.5]])\n",
    "\n",
    "# Appliquer la transformation matricielle à chaque point\n",
    "# Pour multiplier une matrice (n_points x 2) par une matrice (2x2),\n",
    "# on peut utiliser @. NumPy gère correctement la multiplication ligne par ligne.\n",
    "points_transformes = points_originaux @ matrice_transformation\n",
    "\n",
    "\n",
    "# Créer le graphique\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(points_originaux[:, 0], points_originaux[:, 1], color='blue', label='Points Originaux')\n",
    "plt.scatter(points_transformes[:, 0], points_transformes[:, 1], color='red', label='Points Transformés')\n",
    "\n",
    "# Ajouter des flèches pour montrer la transformation de quelques points\n",
    "for i in range(3): # Afficher les transformations pour les 3 premiers points\n",
    "    plt.annotate('', xy=(points_transformes[i, 0], points_transformes[i, 1]),\n",
    "                 xytext=(points_originaux[i, 0], points_originaux[i, 1]),\n",
    "                 arrowprops=dict(arrowstyle='->', color='gray', linewidth=1))\n",
    "\n",
    "\n",
    "plt.xlabel('Axe X') # Label de l'axe x en français\n",
    "plt.ylabel('Axe Y') # Label de l'axe y en français\n",
    "plt.title('Transformation de Points 2D par Multiplication Matricielle') # Titre en français\n",
    "plt.legend() # Afficher la légende\n",
    "plt.grid(True, alpha=0.3) # Afficher la grille\n",
    "plt.axhline(0, color='grey', lw=0.5) # Ligne horizontale à y=0\n",
    "plt.axvline(0, color='grey', lw=0.5) # Ligne verticale à x=0\n",
    "plt.axis('equal') # Assurer que les axes ont la même échelle pour visualiser correctement la transformation\n",
    "plt.show() # 10. Display the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8543ec1c-a7dc-4a3b-a3d0-9f40d7c7a47a",
   "metadata": {},
   "source": [
    "### 3. Statistiques Descriptives : Moyenne, Médiane, Max et Min\n",
    "\n",
    "Les **statistiques descriptives** sont utilisées pour résumer et décrire les caractéristiques principales d'un ensemble de données de manière quantitative. Les mesures de tendance centrale et de dispersion sont essentielles.\n",
    "\n",
    "*   **Moyenne (Mean)** : C'est la somme de toutes les valeurs divisée par le nombre de valeurs. C'est la mesure de tendance centrale la plus courante, représentant le \"centre de masse\" des données. Elle est sensible aux valeurs extrêmes (outliers).\n",
    "\n",
    "*   **Médiane (Median)** : C'est la valeur qui se trouve exactement au milieu d'un ensemble de données ordonné. Si le nombre de données est pair, c'est la moyenne des deux valeurs du milieu. La médiane est une mesure de tendance centrale robuste aux outliers, ce qui la rend utile pour les distributions asymétriques.\n",
    "\n",
    "*   **Maximum (Maximum)** : C'est la valeur la plus élevée dans l'ensemble de données.\n",
    "\n",
    "*   **Minimum (Minimum)** : C'est la valeur la plus basse dans l'ensemble de données.\n",
    "\n",
    "En science des données et en IA :\n",
    "\n",
    "*   Ces statistiques fournissent un **premier aperçu rapide** de la distribution et de la portée des données.\n",
    "*   Elles aident à **identifier les problèmes** dans les données, comme la présence d'outliers (en comparant moyenne et médiane) ou des plages de valeurs inattendues (via max et min).\n",
    "*   Elles sont souvent utilisées dans les **étapes initiales de l'analyse exploratoire des données (EDA)**.\n",
    "*   Le minimum et le maximum définissent la **plage** des données, ce qui peut être important pour la normalisation ou la mise à l'échelle.\n",
    "*   Comprendre la moyenne et la médiane aide à évaluer la **symétrie** ou l'**asymétrie** (skewness) d'une distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502b444-2070-4645-b4fd-29c2539ccb74",
   "metadata": {},
   "source": [
    "# 2. In a new code cell, use NumPy to generate a dataset (e.g., a random sample from a distribution, potentially with some outliers).\n",
    "np.random.seed(42) # for reproducibility\n",
    "# Generate data from a normal distribution\n",
    "data = np.random.normal(loc=50, scale=15, size=200)\n",
    "\n",
    "# Add some outliers\n",
    "outliers = np.array([5, 10, 120, 130])\n",
    "data_with_outliers = np.concatenate((data, outliers))\n",
    "\n",
    "# 3. Calculate the mean, median, maximum, and minimum of the generated dataset using NumPy.\n",
    "mean_value = np.mean(data_with_outliers)\n",
    "median_value = np.median(data_with_outliers)\n",
    "max_value = np.max(data_with_outliers)\n",
    "min_value = np.min(data_with_outliers)\n",
    "\n",
    "# 4. Print the calculated values with descriptive French labels.\n",
    "print(f\"Données générées (avec outliers), premières 10 valeurs : {data_with_outliers[:10]}\")\n",
    "print(f\"\\nStatistiques Descriptives :\")\n",
    "print(f\"  Moyenne : {mean_value:.3f}\")\n",
    "print(f\"  Médiane : {median_value:.3f}\")\n",
    "print(f\"  Maximum : {max_value:.3f}\")\n",
    "print(f\"  Minimum : {min_value:.3f}\")\n",
    "\n",
    "\n",
    "# 5. Use Matplotlib to create a plot that visualizes the dataset and indicates the calculated statistics.\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Create a histogram of the data\n",
    "plt.hist(data_with_outliers, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Add vertical lines for mean and median\n",
    "plt.axvline(mean_value, color='red', linestyle='dashed', linewidth=2, label=f'Moyenne ({mean_value:.3f})')\n",
    "plt.axvline(median_value, color='green', linestyle='dashed', linewidth=2, label=f'Médiane ({median_value:.3f})')\n",
    "\n",
    "# Add horizontal lines or text for max and min\n",
    "plt.text(max_value, plt.ylim()[1] * 0.95, f'Max ({max_value:.1f})', color='purple', ha='right')\n",
    "plt.text(min_value, plt.ylim()[1] * 0.95, f'Min ({min_value:.1f})', color='orange', ha='left')\n",
    "\n",
    "\n",
    "# 6. Add French labels to the axes and a French title to the plot.\n",
    "plt.xlabel('Valeur des données') # Label de l'axe x en français\n",
    "plt.ylabel('Fréquence') # Label de l'axe y en français\n",
    "plt.title('Distribution des données avec Statistiques Descriptives') # Titre en français\n",
    "plt.legend() # Afficher la légende\n",
    "plt.grid(True, alpha=0.3) # Afficher la grille\n",
    "\n",
    "# 7. Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5526ce-841f-4e00-92da-d87bd358cf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 4. Histogramme\n",
    "\n",
    "Un **histogramme** est une représentation graphique de la distribution de fréquence d'une variable continue. Il est construit en divisant l'ensemble des valeurs possibles de la variable en intervalles (appelés \"bins\") et en comptant le nombre d'observations qui tombent dans chaque intervalle. La hauteur de chaque barre de l'histogramme représente la fréquence (ou la densité) des données dans cet intervalle.\n",
    "\n",
    "Les histograms sont essentiels en science des données et en IA pour :\n",
    "\n",
    "*   **Visualiser la distribution :** Ils permettent de voir rapidement la forme de la distribution des données (symétrique, asymétrique, multimodale, etc.).\n",
    "*   **Identifier la tendance centrale et la dispersion :** On peut estimer visuellement où se situe le centre des données et à quel point elles sont étalées.\n",
    "*   **Détecter les outliers :** Les valeurs extrêmes qui se situent loin du corps principal de la distribution peuvent apparaître comme des barres isolées aux extrémités.\n",
    "*   **Comprendre la fréquence des valeurs :** Ils montrent quels intervalles de valeurs sont les plus fréquents dans le jeu de données.\n",
    "*   **Choisir le nombre de bins :** Le choix du nombre de bins peut affecter l'apparence de l'histogramme et la façon dont la distribution est perçue. Un nombre trop faible masque les détails, tandis qu'un nombre trop élevé peut rendre l'histogramme trop granulaire.\n",
    "\n",
    "Bien qu'un histogramme simple ait été utilisé pour visualiser la distribution de probabilité, cette section explore plus en détail sa construction et son interprétation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ee073-476a-4685-99c5-98fabb0fe309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des données pour l'histogramme (par exemple, temps de réponse d'un serveur)\n",
    "np.random.seed(45) # Nouvelle graine\n",
    "# Distribution exponentielle, souvent utilisée pour modéliser les temps d'attente\n",
    "data_histogram = np.random.exponential(scale=10, size=500) # Moyenne de 10\n",
    "\n",
    "print(\"Données générées pour l'histogramme (premières 10 valeurs) :\", data_histogram[:10])\n",
    "\n",
    "# Créer un histogramme avec un nombre de bins par défaut\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1) # Premier subplot\n",
    "plt.hist(data_histogram, bins='auto', alpha=0.7, color='salmon', edgecolor='black') # bins='auto' laisse Matplotlib choisir\n",
    "plt.xlabel('Temps de réponse (secondes)') # Label de l'axe x en français\n",
    "plt.ylabel('Fréquence') # Label de l'axe y en français\n",
    "plt.title('Histogramme (Bins auto)') # Titre en français\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Créer un histogramme avec un nombre de bins différent pour comparaison\n",
    "plt.subplot(1, 2, 2) # Deuxième subplot\n",
    "plt.hist(data_histogram, bins=50, alpha=0.7, color='teal', edgecolor='black') # Plus de bins pour plus de détail\n",
    "plt.xlabel('Temps de réponse (secondes)') # Label de l'axe x en français\n",
    "plt.ylabel('Fréquence') # Label de l'axe y en français\n",
    "plt.title('Histogramme (50 Bins)') # Titre en français\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout() # Ajuster l'espacement\n",
    "plt.show() # Afficher les graphiques\n",
    "\n",
    "# Exemple avec des données multimodales (plusieurs pics)\n",
    "data_multimodal = np.concatenate((np.random.normal(20, 5, 150),\n",
    "                                  np.random.normal(50, 7, 200),\n",
    "                                  np.random.normal(80, 6, 100)))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(data_multimodal, bins=40, alpha=0.7, color='mediumpurple', edgecolor='black')\n",
    "plt.xlabel('Valeur') # Label de l'axe x en français\n",
    "plt.ylabel('Fréquence') # Label de l'axe y en français\n",
    "plt.title('Histogramme de Données Multimodales') # Titre en français\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97c362f-0c6f-405e-91fa-30b9d40c8b2f",
   "metadata": {},
   "source": [
    "## II. Visualisation statistique et distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfb9fdb-6d61-4bbb-b10d-8b488dba3647",
   "metadata": {},
   "source": [
    "### 2. Diagramme en Boîte (Boxplot)\n",
    "\n",
    "Le **diagramme en boîte**, ou **boxplot**, est un outil de visualisation statistique qui résume la distribution d'un ensemble de données en montrant ses quartiles. Il est particulièrement utile pour visualiser la dispersion, l'asymétrie et identifier les valeurs aberrantes (outliers) dans une distribution.\n",
    "\n",
    "Un boxplot typique se compose de :\n",
    "\n",
    "*   **La boîte :** Elle s'étend du premier quartile (Q1) au troisième quartile (Q3). La longueur de la boîte est l'Intervalle Interquartile (IQR = Q3 - Q1).\n",
    "*   **La ligne médiane :** Une ligne à l'intérieur de la boîte indique la position du deuxième quartile (Q2), c'est-à-dire la médiane.\n",
    "*   **Les \"moustaches\" (whiskers) :** Elles s'étendent de la boîte jusqu'aux valeurs minimales et maximales qui ne sont pas considérées comme des outliers. Typiquement, elles s'étendent jusqu'à 1.5 * IQR au-delà de Q1 et Q3.\n",
    "*   **Les outliers :** Les points de données qui se situent au-delà des moustaches sont représentés individuellement sous forme de points.\n",
    "\n",
    "En science des données et en IA :\n",
    "\n",
    "*   Les boxplots sont excellents pour une **analyse exploratoire rapide** de la distribution d'une variable.\n",
    "*   Ils permettent de **comparer facilement les distributions** de plusieurs groupes ou catégories sur un seul graphique.\n",
    "*   Ils sont largement utilisés pour **détecter visuellement les outliers**, ce qui est une étape importante du prétraitement des données.\n",
    "*   La position de la médiane par rapport au centre de la boîte et la longueur relative des moustaches donnent une indication de l'**asymétrie** de la distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ca64c-5acd-4605-b74d-21f284c4b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer des données pour la démonstration du boxplot\n",
    "np.random.seed(44) # Utilisation d'une autre graine\n",
    "# Données normales avec un peu de bruit\n",
    "data_boxplot = np.random.normal(loc=60, scale=15, size=200)\n",
    "\n",
    "# Ajouter quelques outliers\n",
    "outliers_boxplot = np.array([5, 10, 110, 120, 130])\n",
    "data_boxplot_with_outliers = np.concatenate((data_boxplot, outliers_boxplot))\n",
    "\n",
    "# Créer le boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(data_boxplot_with_outliers, patch_artist=True, vert=False,  # vert=False pour un boxplot horizontal\n",
    "            boxprops=dict(facecolor='lightblue', edgecolor='black'),\n",
    "            medianprops=dict(color='red', linewidth=2),\n",
    "            whiskerprops=dict(color='blue'),\n",
    "            capprops=dict(color='blue'),\n",
    "            flierprops=dict(marker='o', color='red', alpha=0.5) # Style des outliers\n",
    "           )\n",
    "\n",
    "# Ajouter des labels et un titre en français\n",
    "plt.xlabel('Valeur des données') # Label de l'axe x en français\n",
    "plt.title('Diagramme en Boîte (Boxplot) de la Distribution des Données') # Titre en français\n",
    "plt.yticks([1], ['Données']) # Label pour l'axe y (pour boxplot horizontal)\n",
    "plt.grid(True, axis='x', alpha=0.3) # Grille sur l'axe x\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n",
    "\n",
    "# Exemple avec plusieurs groupes pour comparaison\n",
    "data_group1 = np.random.normal(loc=50, scale=10, size=100)\n",
    "data_group2 = np.random.normal(loc=60, scale=12, size=150)\n",
    "data_group3 = np.random.normal(loc=55, scale=8, size=120)\n",
    "\n",
    "data_multiple_groups = [data_group1, data_group2, data_group3]\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.boxplot(data_multiple_groups, patch_artist=True,\n",
    "            boxprops=dict(facecolor='lightgreen', edgecolor='black'),\n",
    "            medianprops=dict(color='red', linewidth=2)\n",
    "           )\n",
    "\n",
    "plt.xticks([1, 2, 3], ['Groupe 1', 'Groupe 2', 'Groupe 3']) # Labels pour les groupes\n",
    "plt.xlabel('Groupe') # Label de l'axe x en français\n",
    "plt.ylabel('Valeur des données') # Label de l'axe y en français\n",
    "plt.title('Comparaison des Distributions par Diagramme en Boîte') # Titre en français\n",
    "plt.grid(True, axis='y', alpha=0.3) # Grille sur l'axe y\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658dc675-b487-4338-9c53-e3454d2bce50",
   "metadata": {},
   "source": [
    "## 4. Théorème Central Limite\n",
    "\n",
    "Le **Théorème Central Limite (TCL)** est un concept fondamental en probabilité et en statistique. Il stipule que, sous certaines conditions, la distribution de la somme (ou de la moyenne) d'un grand nombre de variables aléatoires indépendantes et identiquement distribuées (i.i.d.) tend vers une distribution normale (Gaussienne), quelle que soit la distribution d'origine des variables individuelles.\n",
    "\n",
    "L'importance du TCL en science des données et en IA est immense :\n",
    "\n",
    "*   **Inférence Statistique :** Le TCL justifie l'utilisation de la distribution normale pour construire des intervalles de confiance et effectuer des tests d'hypothèses sur les moyennes d'échantillons, même si la distribution de la population d'origine n'est pas normale, à condition que la taille de l'échantillon soit suffisamment grande.\n",
    "*   **Modélisation :** De nombreux modèles statistiques et d'apprentissage automatique qui supposent la normalité (comme la régression linéaire ou certains tests statistiques) peuvent être appliqués à des données agrégées (comme les moyennes) grâce au TCL.\n",
    "*   **Comprendre les phénomènes :** Le TCL explique pourquoi de nombreux phénomènes naturels et sociaux qui résultent de l'accumulation de nombreux petits effets aléatoires (erreurs de mesure, tailles des individus, etc.) suivent approximativement une distribution normale.\n",
    "*   **Réduction de l'incertitude :** En montrant que la moyenne d'un grand échantillon est distribuée normalement et que sa variance diminue à mesure que la taille de l'échantillon augmente, le TCL nous aide à quantifier et à réduire l'incertitude dans nos estimations.\n",
    "\n",
    "En pratique, \"une grande taille d'échantillon\" est souvent considérée comme n > 30, bien que cela dépende de la distribution d'origine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb4ad2-aec9-465c-bff5-30580acba1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Démonstration du Théorème Central Limite\n",
    "# On part d'une distribution non-normale (par exemple, une distribution uniforme)\n",
    "# dont on va échantillonner et calculer les moyennes.\n",
    "\n",
    "# Paramètres de la simulation\n",
    "taille_population = 100000 # Taille de notre \"population\"\n",
    "taille_echantillon = 30 # Taille des échantillons que nous allons prélever\n",
    "nombre_echantillons = 1000 # Nombre d'échantillons à prélever\n",
    "\n",
    "# Générer une population à partir d'une distribution non-normale (Uniforme)\n",
    "population_data = np.random.uniform(low=0, high=10, size=taille_population)\n",
    "\n",
    "# Afficher l'histogramme de la population d'origine (non-normale)\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(population_data, bins=50, density=True, alpha=0.7, color='orange', edgecolor='black')\n",
    "plt.xlabel('Valeur')\n",
    "plt.ylabel('Densité de probabilité')\n",
    "plt.title('Distribution de la Population (Uniforme)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Prélever de nombreux échantillons et calculer la moyenne de chaque échantillon\n",
    "moyennes_echantillons = []\n",
    "for _ in range(nombre_echantillons):\n",
    "    echantillon = np.random.choice(population_data, size=taille_echantillon, replace=True) # Échantillonnage avec remplacement\n",
    "    moyenne_echantillon = np.mean(echantillon)\n",
    "    moyennes_echantillons.append(moyenne_echantillon)\n",
    "\n",
    "# Afficher l'histogramme des moyennes d'échantillons\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(moyennes_echantillons, bins=30, density=True, alpha=0.7, color='teal', edgecolor='black')\n",
    "plt.xlabel('Moyenne de l\\'échantillon')\n",
    "plt.ylabel('Densité de probabilité')\n",
    "plt.title(f'Distribution des Moyennes d\\'Échantillons (n={taille_echantillon})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Superposer une courbe normale théorique pour comparaison\n",
    "from scipy.stats import norm\n",
    "# La moyenne de la distribution des moyennes d'échantillons est la moyenne de la population\n",
    "mean_of_sample_means = np.mean(moyennes_echantillons)\n",
    "# L'écart-type de la distribution des moyennes d'échantillons est l'écart-type de la population / sqrt(n)\n",
    "# On utilise l'écart-type de la population théorique uniforme: std = (high - low) / sqrt(12)\n",
    "std_dev_population = (10 - 0) / np.sqrt(12)\n",
    "std_error = std_dev_population / np.sqrt(taille_echantillon)\n",
    "\n",
    "xmin, xmax = plt.xlim()\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "p = norm.pdf(x, mean_of_sample_means, std_error)\n",
    "plt.plot(x, p, 'k', linewidth=2, label='Distribution Normale Théorique')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout() # Ajuster l'espacement\n",
    "plt.show() # Afficher les graphiques\n",
    "\n",
    "print(f\"\\nMoyenne de la population d'origine : {np.mean(population_data):.3f}\")\n",
    "print(f\"Écart-type de la population d'origine : {np.std(population_data):.3f}\")\n",
    "print(f\"\\nMoyenne des moyennes d'échantillons : {mean_of_sample_means:.3f}\")\n",
    "print(f\"Écart-type des moyennes d'échantillons (Erreur Standard) : {np.std(moyennes_echantillons):.3f}\")\n",
    "print(f\"Erreur Standard théorique : {std_error:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eade39-83c7-43be-96cb-5eb346cffb83",
   "metadata": {},
   "source": [
    "## III. Probabilités et analyse statistique avancée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ef18f-f193-4023-acd9-f386b65da3d3",
   "metadata": {},
   "source": [
    "### 1. Probabilité et loi de probabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da71be8-ec4c-4981-8c1f-365d39f9e65a",
   "metadata": {},
   "source": [
    "#### Définition \n",
    "\n",
    "**Probabilité :** Mesure quantitative qui évalue la chance qu'un événement se réalise, représentée par un nombre réel dans l'intervalle [0, 1]. Pour un événement A appartenant à un espace probabilisé (Ω, P), sa probabilité est notée P(A) avec les propriétés suivantes :\n",
    "* P(A) = 0 indique que l'événement est impossible\n",
    "* P(A) = 1 indique que l'événement est certain\n",
    "* 0 < P(A) < 1 caractérise un événement aléatoire\n",
    "\n",
    "**Loi de probabilité :** Fonction mathématique qui attribue à chaque résultat possible d'une expérience aléatoire sa probabilité d'apparition. Elle fournit une description exhaustive de la répartition des probabilités sur l'ensemble de l'univers des possibles. Par définition, la somme des probabilités de tous les événements élémentaires (cas discret) ou l'intégrale de la densité de probabilité (cas continu) est égale à 1.\n",
    "\n",
    "#### Exemples concrets\n",
    "\n",
    "#### Exemple 1 : Lancer de pièce de monnaie\n",
    "- Probabilité d'obtenir pile : P(Pile) = 1/2 = 0,5\n",
    "- Probabilité d'obtenir face : P(Face) = 1/2 = 0,5\n",
    "- Loi de Bernoulli : expérience aléatoire avec exactement deux résultats possibles (succès/échec), où les probabilités sont complémentaires, c'est-à-dire que P(succès) + P(échec) = 1. Dans cet exemple, si on définit \"pile\" comme un succès avec p = 0,5, alors \"face\" est un échec avec probabilité 1 - p = 0,5. Cette loi modélise toute situation binaire : réussite/échec d'un examen, clic/non-clic sur une publicité, client satisfait/insatisfait, etc.\n",
    "\n",
    "#### Exemple 2 : Tirage de boules dans une urne\n",
    "- Urne contenant 3 boules rouges et 7 boules bleues\n",
    "- Probabilité de tirer une boule rouge : P(Rouge) = 3/10 = 0,3\n",
    "- Probabilité de tirer une boule bleue : P(Bleue) = 7/10 = 0,7\n",
    "\n",
    "#### Exemple 3 : Tirage de cartes\n",
    "- Probabilité de tirer un as dans un jeu de 52 cartes : P(As) = 4/52 = 1/13\n",
    "- Probabilité de tirer un cœur : P(♥) = 13/52 = 1/4\n",
    "\n",
    "#### Exemple 4 : Loi binomiale\n",
    "Pile ou Face : on lance une pièce 10 fois de suite. Quelle est la probabilité d'obtenir exactement 6 \"pile\" sachant que la probabilité d'obtenir \"pile\" à chaque lancer est p = 0,5 ? \n",
    "La loi binomiale B(n=10, p=0,5) modélise cette situation et donne P(X=6) ≈ 0,205 (20,5%). \n",
    "Cette loi est utilisée pour modéliser le nombre de succès dans une série d'expériences indépendantes avec deux issues possibles (succès/échec).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009c5a1-d7d5-4972-a902-64bc33485da0",
   "metadata": {},
   "source": [
    "### Implémentation Python - Loi binomiale\n",
    "\n",
    "#### Objectif de l'exercice\n",
    "Simuler 10 lancers de pièce répétés plusieurs fois pour observer la loi binomiale en action et constater comment les probabilités théoriques se manifestent dans la pratique.\n",
    "\n",
    "#### Comprendre l'approche\n",
    "- **Une expérience** = lancer une pièce 10 fois\n",
    "- **Répétition** = réaliser cette expérience 10 000 fois pour obtenir des statistiques fiables\n",
    "- **Mesure** = compter le nombre de \"pile\" obtenus (entre 0 et 10) pour chaque expérience\n",
    "- **Visualisation** = représenter la distribution des résultats (fréquence de 0 pile, 1 pile, 2 piles... jusqu'à 10 piles)\n",
    "\n",
    "**Réflexion préalable :** Si on lance 10 fois une pièce, quel résultat semble le plus probable : obtenir 5 piles, 0 pile, ou 10 piles ? Pourquoi ?\n",
    "\n",
    "**Paramètres de np.random.binomial :**\n",
    "- n : nombre de lancers par expérience\n",
    "- p : probabilité de succès pour chaque lancer\n",
    "- size : nombre d'expériences à réaliser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f8b2d2-8ebf-4cff-9c83-07e098b0da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# essai introductif\n",
    "\n",
    "# Lancement d'une piède de monnaie\n",
    "lancers = np.random.randint(0, 2, size = 10) # Génère aléatoirement 0 ou 1 x le chiffre affecté à size\n",
    "print(f\"Résultat des 10 lancers: {lancers}\")\n",
    "\n",
    "# Comptage des piles (1)\n",
    "nb_pile = np.sum(lancers) # np.sum() additionne tous les éléments de la liste (donc que les 1) \n",
    "print(f\"Nombre de pile obtenus: {nb_pile}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2f071-9426-45ec-9a88-5978959045fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essai sur 10000 expériences de 10 lancers de pièces\n",
    "\n",
    "n_experiences= 10000\n",
    "n_lancers = 10\n",
    "\n",
    "# fonction binomale\n",
    "resultats = np.random.binomial(n=n_lancers, p=0.5, size = n_experiences)\n",
    "\n",
    "print(f\"Les 10 premiers résultats: {resultats [:10]}\")\n",
    "print(f\"Moyenne des resultats: {np.mean(resultats): .2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cca22-f56e-4a2d-882f-f0ab6b981774",
   "metadata": {},
   "source": [
    "**Analyse des résultats :**\n",
    "\n",
    "La moyenne observée de 4,99 est très proche de l'espérance théorique de 5, calculée par n × p = 10 × 0,5. Cette convergence illustre la loi des grands nombres : plus le nombre d'expériences augmente, plus la moyenne empirique se rapproche de l'espérance mathématique.\n",
    "\n",
    "La variabilité importante des résultats individuels est inhérente à la nature aléatoire de chaque expérience. Bien que la moyenne converge vers 5, les résultats individuels peuvent varier significativement, allant typiquement de 2 à 8 piles pour la majorité des expériences.\n",
    "\n",
    "Cette distribution des résultats autour de la moyenne constitue précisément la loi binomiale que nous cherchons à observer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65ddfa7-edf7-4953-85e7-15d20a1fb04a",
   "metadata": {},
   "source": [
    "### Simulation d'expériences de lancers de pièce\n",
    "\n",
    "Cette expérience simule 10 000 répétitions d'une même expérience aléatoire : lancer une pièce de monnaie 10 fois consécutivement et compter le nombre de \"pile\" obtenus. Pour chaque répétition, le nombre de \"pile\" peut varier entre 0 et 10. L'histogramme qui suit présente la distribution de ces résultats, permettant d'observer visuellement comment les probabilités se manifestent dans la pratique et de mettre en évidence la loi binomiale sous-jacente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3813a2-e86a-45e7-a9b7-c539abc08048",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "# range(0, 12) crée 11 intervalles pour les valeurs 0 à 10\n",
    "plt.hist(resultats, bins=range(0, 12), density=True, alpha=0.7, edgecolor= 'black')\n",
    "plt.title(\"Distribution de la loi binomiale (n=10, p=0.5)\")\n",
    "plt.xlabel(\"Nombre de 'pile' obtenus\")\n",
    "plt.ylabel(\"Probabilité\")\n",
    "plt.xticks((0, 11))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f2aa77-f249-4a07-9e0f-df9d7c9c4b3d",
   "metadata": {},
   "source": [
    "**Observations :**\n",
    "\n",
    "La distribution présente une forme de cloche symétrique, caractéristique de la loi binomiale avec p = 0.5. Le pic, correspondant à la barre la plus haute de l'histogramme, se situe autour de 5 piles et représente le résultat le plus fréquent observé. Cette valeur correspond à l'espérance théorique calculée par n × p = 10 × 0.5 = 5.\n",
    "\n",
    "Les valeurs extrêmes (0 et 10 piles) présentent les probabilités les plus faibles, confirmant leur caractère rare : obtenir uniquement des piles ou uniquement des faces nécessite que tous les lancers donnent le même résultat, événement dont la probabilité est de (0.5)^10 ≈ 0.001, soit environ 0.1%.\n",
    "\n",
    "Cette symétrie s'explique par la probabilité égale de succès et d'échec à chaque lancer. Le pic représente le mode de la distribution, c'est-à-dire la valeur statistiquement la plus probable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5824f896-2940-4509-98e7-9f75559f8583",
   "metadata": {},
   "source": [
    "### 2. Variables indépendantes\n",
    "\n",
    "#### Précision terminologique\n",
    "\n",
    "En statistiques, une **variable** représente une caractéristique mesurable qui peut prendre différentes valeurs. Par exemple : le résultat d'un lancer de dé (1 à 6), la taille d'une personne (en cm), le nombre d'emails reçus par jour. Une **variable aléatoire** est une variable dont la valeur dépend du hasard.\n",
    "\n",
    "#### Définition \n",
    "\n",
    "**Variables aléatoires indépendantes :** Deux variables aléatoires X et Y sont indépendantes si la connaissance de la valeur prise par l'une ne modifie pas la distribution de probabilité de l'autre.\n",
    "\n",
    "**Propriété mathématique :** Pour des variables indépendantes, P(Y = y | X = x) = P(Y = y) pour tous x et y. La probabilité conditionnelle (sachant X) égale la probabilité simple : \"savoir X\" ne change rien à nos prédictions sur Y.\n",
    "\n",
    "**Conséquences importantes :** Si X et Y sont indépendantes, alors :\n",
    "- Cov(X, Y) = 0 (covariance nulle)\n",
    "- E(XY) = E(X) × E(Y) (espérance du produit = produit des espérances)\n",
    "\n",
    "**Attention :** L'inverse n'est pas toujours vrai : Cov(X, Y) = 0 n'implique pas nécessairement l'indépendance (sauf pour les variables gaussiennes).\n",
    "\n",
    "#### Exemples concrets\n",
    "\n",
    "#### Exemple 1 : Deux lancers de dés (indépendants)\n",
    "\n",
    "**Variables :**\n",
    "- X = résultat du premier dé (peut valoir 1, 2, 3, 4, 5 ou 6)\n",
    "- Y = résultat du second dé (peut valoir 1, 2, 3, 4, 5 ou 6)\n",
    "\n",
    "**Indépendance observée :**\n",
    "- Avant de lancer le premier dé : Y a 1/6 de chance de valoir chaque nombre\n",
    "- Après avoir observé X = 4 : Y a toujours 1/6 de chance de valoir chaque nombre\n",
    "- **Conclusion :** La distribution de Y n'a pas changé malgré la connaissance de X. Savoir que X = 4 ne nous aide pas à prédire Y.\n",
    "\n",
    "#### Exemple 2 : Météo de deux villes éloignées (indépendants)\n",
    "\n",
    "**Variables :**\n",
    "- X = pluie à Paris (oui/non)\n",
    "- Y = pluie à Tokyo (oui/non)\n",
    "\n",
    "**Indépendance observée :** Ces villes sont trop éloignées pour que la météo de l'une influence l'autre.\n",
    "\n",
    "#### Contre-exemple : Heures d'étude et note (dépendants)\n",
    "\n",
    "**Variables :**\n",
    "- X = nombre d'heures d'étude\n",
    "- Y = note à l'examen\n",
    "\n",
    "**Dépendance observée :**\n",
    "- Si X = 0 heure → Y sera probablement faible (concentration sur notes basses)\n",
    "- Si X = 50 heures → Y sera probablement élevée (concentration sur notes hautes)\n",
    "- **Conclusion :** Connaître X modifie la distribution attendue de Y. Les variables sont dépendantes.\n",
    "\n",
    "**Note importante :** Bien que nous nous concentrions sur l'indépendance des variables aléatoires en statistique, il existe un lien avec la notion d'indépendance en probabilité. Pour deux variables indépendantes, la probabilité conjointe P(X = x ∩ Y = y) (que X ET Y prennent des valeurs spécifiques simultanément) est égale au produit des probabilités individuelles P(X = x) × P(Y = y). Cette propriété permet de tester mathématiquement l'indépendance entre variables.\n",
    "\n",
    "#### Implémentation Python - Vérification de l'indépendance\n",
    "\n",
    "#### Objectif de l'exercice\n",
    "\n",
    "Simuler le tirage avec remise d'une carte dans deux paquets identiques contenant chacun 4 as (pique, cœur, carreau, trèfle). Chaque paquet est mélangé indépendamment et on tire une carte au hasard de chaque paquet simultanément. Le résultat du tirage dans le premier paquet n'influence en rien celui du second paquet. Nous vérifierons statistiquement cette indépendance par le calcul de corrélation et une visualisation de la distribution conjointe. Cet exercice illustre le principe fondamental d'indépendance statistique entre deux expériences aléatoires identiques mais autonomes, concept essentiel en machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a825e7-a615-4eac-b3be-223444549c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation des tirages\n",
    "# Représentation des as : 0=Pique, 1=Cœur, 2=Carreau, 3=Trèfle\n",
    "\n",
    "n_tirages= 35\n",
    "\n",
    "# Le tirage aléatoires des deux paquets\n",
    "paquet_1= np.random.randint(0, 4, size=n_tirages)\n",
    "paquet_2= np.random.randint(0, 4, size= n_tirages)\n",
    "\n",
    "print(f\"Résultat des 10 premiers tirages du paquet 1: {paquet_1}\")\n",
    "print(f\"Résultat des 10 premiers tirages du paquet 2: {paquet_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3a4a3b-f8af-4a8b-a685-e09d9d59cfaf",
   "metadata": {},
   "source": [
    "**Observation:** Nous constatons que compte tenu de la réccurence des différences de résultats obtenus les tirages (variables) sont bien indépendents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b39eaf5-a1ba-4d0f-83fa-78bb7651f863",
   "metadata": {},
   "source": [
    "#### Visualisation de l'indépendance avec une heatmap\n",
    "\n",
    "Pour démontrer visuellement l'indépendance entre les deux paquets, nous allons créer une carte de chaleur (heatmap) qui affiche la fréquence d'apparition de chaque combinaison possible. Si les variables sont indépendantes, toutes les combinaisons devraient apparaître avec une fréquence similaire (environ 6.25% pour 16 combinaisons possibles).\n",
    "\n",
    "**Outils techniques utilisés :**\n",
    "\n",
    "**NumPy - Construction de la matrice de comptage avec `np.zeros()` :**\n",
    "\n",
    "`np.zeros()` est une fonction NumPy qui crée un tableau (array) rempli de zéros.\n",
    "\n",
    "**Syntaxe de base :**\n",
    "- `np.zeros(5)` → crée un tableau 1D avec 5 zéros : [0. 0. 0. 0. 0.]\n",
    "- `np.zeros((3, 4))` → crée une matrice 2D de 3 lignes × 4 colonnes, toutes à zéro\n",
    "\n",
    "**Application dans notre exercice :**\n",
    "\n",
    "Avec `np.zeros((4, 4))`, nous créons une matrice 4×4 vide servant de tableau de comptage, similaire à un tableau Excel de 4 lignes et 4 colonnes où toutes les cases contiennent initialement 0.\n",
    "\n",
    "**Mécanisme de comptage :**\n",
    "1. Au départ : toutes les cases valent 0\n",
    "2. Quand on tire Pique (0) du paquet 1 et Cœur (1) du paquet 2 → `matrice[0, 1] += 1`\n",
    "3. Cette case passe de 0 à 1\n",
    "4. Si cette combinaison réapparaît → elle passe à 2, puis 3, etc.\n",
    "5. À la fin, chaque case contient le nombre total d'occurrences de sa combinaison respective\n",
    "\n",
    "La division vectorisée convertit ensuite ces comptages en pourcentages pour faciliter l'interprétation.\n",
    "\n",
    "**Seaborn - Visualisation des données :**\n",
    "\n",
    "`sns.heatmap()` transforme la matrice numérique en carte de chaleur où l'intensité des couleurs représente les fréquences. Cette visualisation permet une lecture intuitive immédiate de la distribution : des couleurs uniformes indiquent l'indépendance.\n",
    "\n",
    "**Matplotlib - Support de rendu :**\n",
    "\n",
    "Fournit l'infrastructure graphique sous-jacente à Seaborn pour créer et afficher la figure. Gère la fenêtre d'affichage, les axes et la mise en page finale.\n",
    "\n",
    "**Interprétation attendue :**\n",
    "\n",
    "Si les deux paquets sont réellement indépendants, la heatmap devrait montrer une distribution quasi-uniforme avec toutes les cases affichant des valeurs proches de 6.25% et des couleurs homogènes. Aucune combinaison ne devrait être significativement sur-représentée ou sous-représentée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13965791-8c36-423f-88fd-7428503a0851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Étape 1 : Simulation des tirages\n",
    "# Représentation des as : 0=Pique, 1=Cœur, 2=Carreau, 3=Trèfle\n",
    "n_tirages = 1000\n",
    "\n",
    "# Paquet 1 : tirage aléatoire d'un as\n",
    "paquet_1 = np.random.randint(0, 4, size=n_tirages)\n",
    "\n",
    "# Paquet 2 : tirage aléatoire d'un as \n",
    "paquet_2 = np.random.randint(0, 4, size=n_tirages)\n",
    "\n",
    "# Les lignes représentent les as du paquet 1, les colonnes ceux du paquet 2\n",
    "matrice_comptage = np.zeros((4, 4))\n",
    "\n",
    "# Compter les occurrences de chaque paire\n",
    "# Cette boucle parcourt chaque tirage simultanément dans les deux paquets\n",
    "for i in range(len(paquet_1)):\n",
    "    # Pour le i-ème tirage :\n",
    "    # - paquet_1[i] donne l'as tiré du premier paquet (0=Pique, 1=Cœur, 2=Carreau, 3=Trèfle)\n",
    "    # - paquet_2[i] donne l'as tiré du deuxième paquet\n",
    "    # - matrice_comptage[ligne, colonne] accède à la case correspondante\n",
    "    # - += 1 incrémente le compteur de cette combinaison spécifique\n",
    "    # Exemple : si paquet_1[i] = 1 (Cœur) et paquet_2[i] = 3 (Trèfle)\n",
    "    # alors on ajoute 1 à matrice_comptage[1, 3]\n",
    "    matrice_comptage[paquet_1[i], paquet_2[i]] += 1\n",
    "\n",
    "# convertir en %\n",
    "pourcentage = (matrice_comptage / n_tirages) * 100\n",
    "\n",
    "# Étape 3 : Visualisation avec heatmap\n",
    "# Définir les labels des as\n",
    "labels = ['Pique', 'Cœur', 'Carreau', 'Trèfle']\n",
    "\n",
    "# création du heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(pourcentage,  # Matrice de données (en %)\n",
    "            annot=True,  # affiche les valeurs dans chaque case\n",
    "            fmt='.2f',  # format des annotations: 2 décimales\n",
    "            cmap='YlOrRd',  # choix des couleurs (jaune → orange → rouge)\n",
    "            cbar_kws={'label': 'Fréquence (%)'},  \n",
    "            xticklabels=labels,  # pique, coeur, carreau, trefle\n",
    "            yticklabels=labels)  # Idem\n",
    "\n",
    "# Titres\n",
    "plt.title('Distribution des combinaisons - Deux paquets indépendants')\n",
    "plt.xlabel('Paquet 2') \n",
    "plt.ylabel('Paquet 1')  \n",
    "plt.tight_layout()  # ajuste automatiquement l'espacement entre les éléments du graphique\n",
    "plt.show()\n",
    "\n",
    "# Afficher les valeurs numériques\n",
    "print(\"\\nMatrice de fréquences (en %) :\")\n",
    "print(pourcentage)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88acb9-0cce-4ed7-b690-740e1512a4e5",
   "metadata": {},
   "source": [
    "#### Conclusion sur l'indépendance des variables\n",
    "\n",
    "#### Confirmation de l'indépendance\n",
    "\n",
    "On observe que la distribution des combinaisons entre les deux paquets suit parfaitement le comportement attendu pour des variables indépendantes.\n",
    "\n",
    "On constate que :\n",
    "- Toutes les combinaisons possibles apparaissent avec des fréquences similaires\n",
    "- La majorité des valeurs se situent autour de la probabilité théorique de 6,25%\n",
    "- Aucun pattern particulier ni de combinaison privilégiée n'est détecté\n",
    "- Les écarts observés entre 4,4% et 7,4% correspondent aux fluctuations statistiques attendues\n",
    "\n",
    "#### Interprétation statistique\n",
    "\n",
    "On peut affirmer que les deux paquets se comportent comme des variables aléatoires indépendantes. Le tirage d'un as dans un paquet n'influence pas le tirage dans l'autre paquet. La dispersion des valeurs autour de 6,25% est tout à fait normale dans un processus aléatoire avec cet effectif d'échantillon.\n",
    "\n",
    "#### Validation du modèle\n",
    "\n",
    "On a démontré empiriquement que le modèle de tirages indépendants est validé par les données observées. Cette expérience illustre de manière concrète le concept d'indépendance statistique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bacba-0aa2-45fc-a749-f62eaaae44fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3. Espérance, variance et écart-type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a09826-b59f-4205-a2b2-c824441fd8fc",
   "metadata": {},
   "source": [
    "### 3. ESPÉRANCE, VARIANCE ET ÉCART-TYPE\n",
    "\n",
    "---\n",
    "\n",
    "### A. ESPÉRANCE - E(X) : \"La moyenne qu'on attend\"\n",
    "\n",
    "#### C'est quoi l'espérance ?\n",
    "\n",
    "L'**espérance**, c'est simplement **la moyenne qu'on obtiendrait si on répétait l'expérience plein de fois**. C'est le résultat \"typique\" qu'on peut attendre.\n",
    "\n",
    "#### Comment la calculer ?\n",
    "\n",
    "**Formule : E(X) = Σ [xi × P(X = xi)]**\n",
    "\n",
    "Ça peut paraître compliqué, mais c'est simple :\n",
    "1. On prend chaque résultat possible\n",
    "2. On le multiplie par sa probabilité (ses chances d'arriver)\n",
    "3. On additionne tout\n",
    "\n",
    "#### Exemple simple : lancer de dé\n",
    "\n",
    "Un dé a 6 faces : 1, 2, 3, 4, 5, 6. Chaque face a 1 chance sur 6 d'apparaître.\n",
    "\n",
    "**Calcul :**\n",
    "\n",
    "E(X) = (1 × 1/6) + (2 × 1/6) + (3 × 1/6) + (4 × 1/6) + (5 × 1/6) + (6 × 1/6)\n",
    "     = (1 + 2 + 3 + 4 + 5 + 6) / 6\n",
    "     = 21 / 6\n",
    "     = **3,5**\n",
    "\n",
    "**Ce que ça veut dire :** Si vous lancez le dé 1000 fois et que vous faites la moyenne de tous vos résultats, vous trouverez environ 3,5.\n",
    "\n",
    "**Note importante :** Vous n'obtiendrez jamais 3,5 sur un seul lancer ! C'est juste la moyenne sur le long terme.\n",
    "\n",
    "#### Cas particulier : quand tous les résultats ont les mêmes chances\n",
    "\n",
    "Si tous les résultats sont équiprobables (mêmes chances), c'est encore plus simple :\n",
    "\n",
    "**E(X) = (Somme de toutes les valeurs) / (Nombre de valeurs)**\n",
    "\n",
    "C'est la moyenne qu'on connaît tous !\n",
    "\n",
    "#### Exemple avec des chances différentes : le jeu de grattage\n",
    "\n",
    "Un ticket de grattage coûte 3€. Voici ce qu'on peut gagner :\n",
    "- 90% de chance : 0€ (rien)\n",
    "- 8% de chance : 5€\n",
    "- 2% de chance : 100€\n",
    "\n",
    "**Calcul du gain moyen :**\n",
    "\n",
    "E(Gain) = (0 × 0,90) + (5 × 0,08) + (100 × 0,02)\n",
    "        = 0 + 0,40 + 2,00\n",
    "        = **2,40€**\n",
    "\n",
    "Le ticket coûte 3€, donc en moyenne on perd : 2,40€ - 3€ = **-0,60€**\n",
    "\n",
    "**Conclusion :** En moyenne, on perd 60 centimes à chaque fois qu'on joue. C'est comme ça que le vendeur gagne de l'argent !\n",
    "\n",
    "---\n",
    "\n",
    "### B. VARIANCE - Var(X) : \"Mesurer si c'est dispersé\"\n",
    "\n",
    "#### C'est quoi la variance ?\n",
    "\n",
    "La variance mesure **à quel point les résultats sont éloignés de la moyenne**. En d'autres termes : est-ce que tout le monde a des résultats similaires, ou y a-t-il de grandes différences ?\n",
    "\n",
    "#### Comment la calculer ?\n",
    "\n",
    "**Formule : Var(X) = E[(X - μ)²]**\n",
    "\n",
    "Traduction en français :\n",
    "1. On calcule l'écart entre chaque valeur et la moyenne (X - μ)\n",
    "2. On élève chaque écart au carré (pour éviter que les + et - s'annulent)\n",
    "3. On fait la moyenne de tous ces carrés\n",
    "\n",
    "#### Pourquoi on élève au carré ?\n",
    "\n",
    "**Le problème sans le carré :**\n",
    "\n",
    "Imaginons 3 personnes mesurant : 160 cm, 170 cm, 180 cm (moyenne = 170 cm)\n",
    "\n",
    "**Écarts par rapport à la moyenne :**\n",
    "- 160 - 170 = **-10**\n",
    "- 170 - 170 = **0**\n",
    "- 180 - 170 = **+10**\n",
    "\n",
    "Si on fait la moyenne de ces écarts : (-10 + 0 + 10) / 3 = **0**\n",
    "\n",
    "Problème ! Ça dit qu'il n'y a pas d'écart, alors qu'il y en a bien un de 10 cm !\n",
    "\n",
    "**La solution avec le carré :**\n",
    "- (-10)² = **100**\n",
    "- (0)² = **0**\n",
    "- (10)² = **100**\n",
    "\n",
    "Moyenne : (100 + 0 + 100) / 3 = **66,7**\n",
    "\n",
    "Maintenant on a bien une mesure de la dispersion !\n",
    "\n",
    "#### Version plus rapide à calculer\n",
    "\n",
    "**Formule : Var(X) = E(X²) - [E(X)]²**\n",
    "\n",
    "C'est mathématiquement équivalent, mais plus rapide :\n",
    "1. On calcule la moyenne des carrés : E(X²)\n",
    "2. On calcule le carré de la moyenne : [E(X)]²\n",
    "3. On soustrait : Var(X) = E(X²) - [E(X)]²\n",
    "\n",
    "#### Exemple concret : notes d'examen\n",
    "\n",
    "**Classe A :**\n",
    "Tout le monde a entre 12 et 14 → **Variance faible** (groupe homogène)\n",
    "\n",
    "**Classe B :**\n",
    "Certains ont 5, d'autres 18 → **Variance élevée** (groupe hétérogène)\n",
    "\n",
    "**Interprétation :** Plus la variance est grande, plus il y a de différences entre les individus.\n",
    "\n",
    "---\n",
    "\n",
    "### C. ÉCART-TYPE - σ : \"La variance qu'on comprend\"\n",
    "\n",
    "#### C'est quoi l'écart-type ?\n",
    "\n",
    "L'écart-type, c'est simplement **la racine carrée de la variance**.\n",
    "\n",
    "**Formule : σ = √Var(X)**\n",
    "\n",
    "#### Pourquoi faire ça ?\n",
    "\n",
    "**Le problème de la variance :** elle est dans une unité bizarre !\n",
    "\n",
    "**Exemple avec des tailles :**\n",
    "- Les tailles sont mesurées en **cm**\n",
    "- La variance est en **cm²** (centimètres carrés !)\n",
    "\n",
    "Comment interpréter \"100 cm² de taille\" ? Ça n'a pas de sens !\n",
    "\n",
    "**La solution : l'écart-type**\n",
    "\n",
    "En prenant la racine carrée, on revient à l'unité d'origine :\n",
    "- Variance = 100 cm²\n",
    "- Écart-type = √100 = **10 cm**\n",
    "\n",
    "Maintenant on peut dire : \"Les tailles varient d'environ ±10 cm autour de la moyenne.\"\n",
    "\n",
    "#### Exemple complet : tailles d'adultes\n",
    "\n",
    "- Moyenne : 170 cm\n",
    "- Écart-type : 10 cm\n",
    "\n",
    "**Ce que ça signifie concrètement :**\n",
    "- La plupart des gens (environ 68%) mesurent entre **160 cm et 180 cm** (170 ± 10)\n",
    "- Presque tout le monde (95%) mesure entre **150 cm et 190 cm** (170 ± 20)\n",
    "\n",
    "#### Exemple : lancer de dé\n",
    "\n",
    "On a vu que l'espérance est 3,5 et la variance est environ 2,92.\n",
    "\n",
    "**Écart-type :**\n",
    "σ = √2,92 ≈ **1,71**\n",
    "\n",
    "**Interprétation :** Les résultats du dé s'écartent typiquement de ±1,7 autour de 3,5.\n",
    "\n",
    "Donc la plupart des résultats sont entre :\n",
    "- 3,5 - 1,7 = **1,8**\n",
    "- 3,5 + 1,7 = **5,2**\n",
    "\n",
    "Ça correspond bien aux valeurs possibles du dé (1 à 6) !\n",
    "\n",
    "---\n",
    "\n",
    "### Résumé visuel\n",
    "\n",
    "| Concept | Question | Réponse | Unité |\n",
    "|---------|----------|---------|-------|\n",
    "| **Espérance** | Quelle est la moyenne attendue ? | Le centre | cm, €, points... |\n",
    "| **Variance** | Les valeurs sont-elles dispersées ? | Dispersion² | cm², €²... (difficile) |\n",
    "| **Écart-type** | Les valeurs sont-elles dispersées ? | Dispersion | cm, €, points... (facile) |\n",
    "\n",
    "**Conseil pratique :**\n",
    "- On **calcule** la variance (c'est plus pratique mathématiquement)\n",
    "- On **communique** l'écart-type (c'est plus facile à comprendre)\n",
    "\n",
    "---\n",
    "\n",
    "### Un dernier exemple pour tout comprendre\n",
    "\n",
    "**Deux classes passent le même examen (note sur 20) :**\n",
    "\n",
    "**Classe A :**\n",
    "- Moyenne : 12\n",
    "- Écart-type : 1\n",
    "- **Interprétation :** Tout le monde a entre 11 et 13. Classe très homogène.\n",
    "\n",
    "**Classe B :**\n",
    "- Moyenne : 12\n",
    "- Écart-type : 5\n",
    "- **Interprétation :** Certains ont 7, d'autres 17. Classe très hétérogène.\n",
    "\n",
    "**Conclusion :** Même moyenne, mais dispersion très différente ! L'écart-type nous donne cette information précieuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb111ac2-a9b2-4c56-820d-cd899e6d75b4",
   "metadata": {},
   "source": [
    "#### Objectif de l'exercice\n",
    "\n",
    "Simuler les résultats d’un examen dont les **notes suivent une distribution réaliste sur 20 points**.\n",
    "L’objectif est de **vérifier que, sur un grand nombre d’élèves, la moyenne empirique converge vers l’espérance théorique**, puis de **calculer la variance et l’écart-type** afin de mesurer la **dispersion des notes**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145aab51-22d8-49b4-9d6a-87cd553f7866",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Démonstration de l'espérance avec les note d'une classe\n",
    "\n",
    "# Distribution des notes sur 20\n",
    "notes_possibles = [6, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "probabilites = [0.02, 0.05, 0.08, 0.10, 0.15, 0.18, 0.15, 0.12, 0.08, 0.04, 0.02, 0.01] #Probablité d'obtenir chacune des notes\n",
    "\n",
    "# Vérification que la somme des probabilités fait bien 1\n",
    "print(f\"Somme des probabilités: {sum(probabilites)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbd63e1-67dc-40ea-b0b2-0c5e66632e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simuler les notes des élèves\n",
    "\n",
    "n_eleves = 100\n",
    "\n",
    "# Notes selon les probabilités définies\n",
    "notes = np.random.choice(notes_possibles, size=n_eleves, p=probabilites)\n",
    "\n",
    "#Premières 20 notes\n",
    "print(f\"Les 20 premières notes: {notes [:20]}\")\n",
    "\n",
    "# Conversion en array pour multiplication élément par élément\n",
    "notes_possibles = np.array(notes_possibles)\n",
    "probabilites   = np.array(probabilites)\n",
    "# Calcul de la moyenne empirique et théorique\n",
    "esperance_theorique = np.sum(notes_possibles * probabilites)\n",
    "print(f\"Espérance théorique : {esperance_theorique:.2f}\")\n",
    "\n",
    "moyenne_empirique = np.mean(notes)\n",
    "print(f\"\\nMoyenne de la classe (empirique) : {moyenne_empirique:.2f}\")\n",
    "\n",
    "# Calculs variance et ecart-type\n",
    "variance_empirique = np.var(notes)\n",
    "ecart_type_empirique = np.std(notes)\n",
    "print(f\"Variance empirique : {variance_empirique:.2f}\")\n",
    "print(f\"Écart-type empirique : {ecart_type_empirique:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e54a6d-be70-4a4e-a5a8-e3924b8e08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(notes, bins=range(5,21), kde=False, color='skyblue', edgecolor='black')\n",
    "\n",
    "# Ligne espérance théorique\n",
    "plt.axvline(esperance_theorique, color='red', linestyle='--', linewidth=2, label=f'Espérance = {esperance_theorique:.2f}')\n",
    "\n",
    "# Zone de ± écart-type autour de la moyenne empirique\n",
    "plt.axvline(moyenne_empirique, color='green', linestyle='-', linewidth=2, label=f'Moyenne empirique = {moyenne_empirique:.2f}')\n",
    "plt.fill_betweenx([0, plt.gca().get_ylim()[1]], \n",
    "                  moyenne_empirique - ecart_type_empirique, \n",
    "                  moyenne_empirique + ecart_type_empirique, \n",
    "                  color='orange', alpha=0.2, label=f'Écart-type ≈ {ecart_type_empirique:.2f}')\n",
    "\n",
    "plt.title(\"Distribution simulée des notes avec espérance, variance et écart-type\")\n",
    "plt.xlabel(\"Notes\")\n",
    "plt.ylabel(\"Nombre d'élèves\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12becfb-83ec-4331-98e1-b312f51068b6",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "\n",
    "- **Espérance théorique : 12.97**  \n",
    "  Moyenne attendue si l’on observe un très grand nombre d’élèves selon la distribution définie. Représente la tendance centrale des notes.\n",
    "\n",
    "- **Moyenne empirique : 12.96**  \n",
    "  Calculée à partir des 5000 notes simulées. Très proche de l’espérance théorique, ce qui montre que la simulation fonctionne bien et illustre la loi des grands nombres.\n",
    "\n",
    "- **Variance empirique : 6.43**  \n",
    "  Mesure la dispersion des notes autour de la moyenne. Une variance modérée indique que certaines notes s’écartent sensiblement de la moyenne.\n",
    "\n",
    "- **Écart-type empirique : 2.54**  \n",
    "  Racine carrée de la variance, exprimée dans la même unité que les notes. La majorité des notes se situe environ dans l’intervalle `[12.96 - 2.54, 12.96 + 2.54] ≈ [10.4, 15.5]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27dd897-ce02-419a-bf26-b515d8972b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dc937e-81ea-456d-a2ad-d6f5f7984626",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda Fresh)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
